\documentclass[12pt,a4paper]{report}
\usepackage[utf8]{inputenc}
\usepackage[vietnamese]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{geometry}
\usepackage{fancyhdr}
\usepackage{titlesec}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{array}
\usepackage{longtable}

% Page setup
\geometry{left=3cm,right=2cm,top=3cm,bottom=3cm}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\leftmark}
\fancyhead[R]{\thepage}
\fancyfoot[C]{}

% Code listing style
\lstset{
    language=Python,
    basicstyle=\ttfamily\small,
    keywordstyle=\color{blue}\bfseries,
    commentstyle=\color{green!60!black},
    stringstyle=\color{red},
    numbers=left,
    numberstyle=\tiny\color{gray},
    stepnumber=1,
    numbersep=5pt,
    backgroundcolor=\color{gray!10},
    frame=single,
    breaklines=true,
    breakatwhitespace=true,
    tabsize=4,
    showstringspaces=false
}

% Title information
\title{
    \textbf{HỆ THỐNG PHÁT HIỆN GIAN LẬN THẺ TÍN DỤNG\\ 
    SỬ DỤNG SPARK ML VÀ KAFKA STREAMING\\
    ĐƯỢC ĐIỀU PHỐI BỞI APACHE AIRFLOW}
    \vspace{1cm}
    \large{BÁO CÁO CUỐI KỲ MÔN BIG DATA}
}
\author{
    \textbf{Nhóm 2}\\
    Phan Văn Tài - 2202081\\
    Phan Minh Thuy - 2202079\\
    \vspace{0.5cm}
    \textbf{Giảng viên hướng dẫn:}\\
    Dr. Cao Tiến Dũng\\
    \vspace{0.5cm}
    \textbf{Khoa Công nghệ Thông tin}\\
    \textbf{Ngành Khoa học Máy tính}
}
\date{\today}

\begin{document}

% Cover page
\maketitle
\thispagestyle{empty}
\newpage

% Table of contents
\tableofcontents
\newpage

% List of figures
\listoffigures
\newpage

% List of tables
\listoftables
\newpage

% ============================================
% CHAPTER 1: INTRODUCTION
% ============================================
\chapter{GIỚI THIỆU}
\section{Tổng quan}

Trong thời đại số hóa hiện nay, gian lận thẻ tín dụng đang trở thành một vấn đề nghiêm trọng gây thiệt hại hàng tỷ USD mỗi năm cho các tổ chức tài chính trên toàn thế giới. Việc phát hiện và ngăn chặn các giao dịch gian lận một cách nhanh chóng và chính xác là thách thức lớn đối với ngành ngân hàng và tài chính.

Dự án này trình bày một hệ thống phát hiện gian lận thẻ tín dụng thời gian thực sử dụng Apache Spark ML để huấn luyện mô hình machine learning, Apache Kafka để xử lý dữ liệu streaming, và Apache Airflow để điều phối toàn bộ quy trình từ khởi động infrastructure đến training model và thực hiện dự đoán.

\section{Mục tiêu}

Dự án nhằm đạt được các mục tiêu sau:

\begin{itemize}
    \item Xây dựng một pipeline hoàn chỉnh để phát hiện gian lận thẻ tín dụng sử dụng Spark ML với thuật toán Random Forest
    \item Triển khai hệ thống streaming thời gian thực sử dụng Kafka để xử lý dữ liệu giao dịch
    \item Sử dụng Apache Airflow để tự động hóa và điều phối toàn bộ quy trình từ khởi động services đến training và prediction
    \item Đánh giá hiệu suất của hệ thống trên môi trường phân tán với nhiều máy chủ
\end{itemize}

\section{Phạm vi dự án}

Dự án tập trung vào:

\begin{itemize}
    \item Dataset: Credit Card Fraud Detection từ Kaggle
    \item Thuật toán ML: Random Forest Classifier trong Spark ML
    \item Infrastructure: Hadoop HDFS, Apache Spark, Apache Kafka, Apache Airflow
    \item Môi trường triển khai: 4 máy chủ (Spark Master/Hadoop, Kafka, Airflow, Spark Worker)
    \item Điều phối: Apache Airflow với Celery executor sử dụng IP-based queue
\end{itemize}

\section{Cấu trúc báo cáo}

Báo cáo được tổ chức thành các chương như sau:

\begin{itemize}
    \item \textbf{Chương 1: Giới thiệu} - Tổng quan về dự án, mục tiêu và phạm vi
    \item \textbf{Chương 2: Cơ sở lý thuyết} - Các công nghệ và khái niệm được sử dụng
    \item \textbf{Chương 3: Phân tích và thiết kế hệ thống} - Kiến trúc hệ thống và thiết kế pipeline
    \item \textbf{Chương 4: Triển khai và thực nghiệm} - Chi tiết triển khai và kết quả thực nghiệm
    \item \textbf{Chương 5: Đánh giá và hạn chế} - Phân tích hiệu suất và các hạn chế của hệ thống
    \item \textbf{Chương 6: Kết luận và hướng phát triển} - Tổng kết và đề xuất cải tiến
\end{itemize}

% ============================================
% CHAPTER 2: THEORETICAL BACKGROUND
% ============================================
\chapter{CƠ SỞ LÝ THUYẾT}

\section{Apache Spark và Spark ML}

\subsection{Apache Spark}

Apache Spark là một framework xử lý dữ liệu phân tán mã nguồn mở được phát triển bởi UC Berkeley AMPLab. Spark cung cấp khả năng xử lý dữ liệu lớn với tốc độ cao nhờ tính toán trong bộ nhớ (in-memory computing).

\textbf{Đặc điểm chính:}
\begin{itemize}
    \item \textbf{Tốc độ}: Nhanh hơn Hadoop MapReduce 10-100 lần nhờ tính toán trong bộ nhớ
    \item \textbf{Dễ sử dụng}: Hỗ trợ nhiều ngôn ngữ (Scala, Java, Python, R)
    \item \textbf{Tính toán tổng quát}: Hỗ trợ SQL, Streaming, Machine Learning, Graph Processing
    \item \textbf{Tích hợp}: Hoạt động với Hadoop, Kubernetes, Mesos, và các hệ thống lưu trữ khác
\end{itemize}

\subsection{Spark MLlib và Spark ML}

Spark MLlib là thư viện machine learning của Spark, cung cấp hai API chính:

\begin{itemize}
    \item \textbf{MLlib (RDD-based)}: API cũ dựa trên RDD, hiện đang ở chế độ maintenance
    \item \textbf{ML (DataFrame-based)}: API mới dựa trên DataFrame, được khuyến nghị sử dụng
\end{itemize}

\textbf{Ưu điểm của Spark ML:}
\begin{itemize}
    \item Pipeline API cho phép kết hợp nhiều bước xử lý
    \item Tối ưu hóa tự động với Catalyst optimizer
    \item Hỗ trợ tốt cho structured data với DataFrame
    \item Tích hợp với Spark Streaming cho real-time prediction
\end{itemize}

\subsection{Random Forest trong Spark ML}

Random Forest là một thuật toán ensemble learning sử dụng nhiều cây quyết định (decision trees). Trong Spark ML, Random Forest được triển khai với các đặc điểm:

\begin{itemize}
    \item \textbf{Parallelization}: Mỗi cây được huấn luyện song song
    \item \textbf{Feature sampling}: Mỗi cây chỉ sử dụng một tập con các features
    \item \textbf{Bootstrap sampling}: Mỗi cây được huấn luyện trên một tập dữ liệu khác nhau
    \item \textbf{Voting}: Kết quả cuối cùng là majority vote của tất cả các cây
\end{itemize}

\section{Apache Kafka}

Apache Kafka là một nền tảng streaming phân tán mã nguồn mở được phát triển bởi LinkedIn. Kafka được thiết kế để xử lý dữ liệu streaming với throughput cao và độ trễ thấp.

\textbf{Kiến trúc Kafka:}
\begin{itemize}
    \item \textbf{Producer}: Gửi dữ liệu đến Kafka topics
    \item \textbf{Consumer}: Đọc dữ liệu từ Kafka topics
    \item \textbf{Broker}: Máy chủ Kafka lưu trữ và quản lý topics
    \item \textbf{Topic}: Luồng dữ liệu được phân loại theo chủ đề
    \item \textbf{Partition}: Chia nhỏ topic để tăng throughput và khả năng mở rộng
    \item \textbf{Zookeeper}: Quản lý metadata và coordination
\end{itemize}

\textbf{Ưu điểm của Kafka:}
\begin{itemize}
    \item \textbf{High throughput}: Có thể xử lý hàng triệu messages mỗi giây
    \item \textbf{Scalability}: Dễ dàng mở rộng bằng cách thêm brokers
    \item \textbf{Durability}: Dữ liệu được lưu trữ trên disk với replication
    \item \textbf{Real-time}: Độ trễ thấp, phù hợp cho real-time processing
\end{itemize}

\section{Apache Airflow}

Apache Airflow là một nền tảng mã nguồn mở để lập trình, lên lịch và giám sát workflows. Airflow sử dụng Python để định nghĩa workflows dưới dạng Directed Acyclic Graphs (DAGs).

\textbf{Thành phần chính:}
\begin{itemize}
    \item \textbf{Web Server}: Giao diện web để quản lý và giám sát DAGs
    \item \textbf{Scheduler}: Lên lịch và trigger tasks
    \item \textbf{Executor}: Thực thi tasks trên workers
    \item \textbf{Metadata Database}: Lưu trữ trạng thái của DAGs và tasks
    \item \textbf{Workers}: Máy chủ thực thi các tasks
\end{itemize}

\textbf{Celery Executor:}
Celery Executor cho phép Airflow phân phối tasks đến các Celery workers chạy trên nhiều máy chủ khác nhau. Trong dự án này, chúng tôi sử dụng IP-based queue thay vì Redis queue.

\section{Hadoop HDFS}

Hadoop Distributed File System (HDFS) là hệ thống file phân tán được thiết kế để lưu trữ dữ liệu lớn trên các cluster máy tính.

\textbf{Kiến trúc HDFS:}
\begin{itemize}
    \item \textbf{NameNode}: Quản lý metadata và namespace của file system
    \item \textbf{DataNode}: Lưu trữ dữ liệu thực tế
    \item \textbf{Secondary NameNode}: Hỗ trợ NameNode trong việc quản lý metadata
\end{itemize}

\textbf{Đặc điểm:}
\begin{itemize}
    \item \textbf{Fault tolerance}: Dữ liệu được replicate trên nhiều DataNodes
    \item \textbf{High availability}: Có thể cấu hình High Availability với nhiều NameNodes
    \item \textbf{Scalability}: Có thể mở rộng đến hàng nghìn nodes
    \item \textbf{Cost-effective}: Chạy trên commodity hardware
\end{itemize}

% ============================================
% CHAPTER 3: SYSTEM ANALYSIS AND DESIGN
% ============================================
\chapter{PHÂN TÍCH VÀ THIẾT KẾ HỆ THỐNG}

\section{Kiến trúc tổng thể}

Hệ thống được thiết kế với kiến trúc phân tán gồm 4 thành phần chính:

\begin{enumerate}
    \item \textbf{Máy chủ Spark Master và Hadoop (192.168.80.52)}: Chạy Spark Master, Hadoop NameNode và DataNode. Lưu trữ dữ liệu training (train.csv) và streaming (stream.csv) trên HDFS
    \item \textbf{Máy chủ Kafka (192.168.80.122)}: Chạy Kafka Broker và Zookeeper
    \item \textbf{Máy chủ Airflow (192.168.80.98)}: Chạy Airflow Web Server và Scheduler
    \item \textbf{Máy chủ Spark Worker (192.168.80.130)}: Chạy Spark Worker
\end{enumerate}

% Hình 3.1: Kiến trúc hệ thống tổng thể
\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{architecture_diagram.png}
\caption{Kiến trúc hệ thống tổng thể}
\label{fig:architecture}
\end{figure}

\section{Dataset}

\subsection{Mô tả dataset}

Dự án sử dụng dataset \textbf{Credit Card Fraud Detection} từ Kaggle. Dataset này chứa các giao dịch thẻ tín dụng đã được mã hóa PCA (Principal Component Analysis) để bảo vệ thông tin nhạy cảm.

\textbf{Đặc điểm dataset:}
\begin{itemize}
    \item \textbf{Số lượng features}: 30 features (V1-V28, Time, Amount)
    \item \textbf{Target variable}: Class (0 = Normal, 1 = Fraud)
    \item \textbf{Kích thước}: Khoảng 284,807 giao dịch
    \item \textbf{Class imbalance}: Rất mất cân bằng (chỉ khoảng 0.172\% là fraud)
\end{itemize}

\subsection{Chia dữ liệu}

Dataset được chia thành 2 phần:

\begin{enumerate}
    \item \textbf{Training data (train.csv)}: 80\% dữ liệu để huấn luyện mô hình, được lưu trên HDFS tại \texttt{hdfs://192.168.80.52:9000/data/train.csv}
    \item \textbf{Streaming data (stream.csv)}: 20\% dữ liệu còn lại để mô phỏng streaming, được lưu trên HDFS tại \texttt{hdfs://192.168.80.52:9000/data/stream.csv}
\end{enumerate}

\section{Flow xử lý dữ liệu}

Quy trình xử lý dữ liệu trong hệ thống được mô tả qua các bước sau:

\begin{enumerate}
    \item \textbf{Khởi động Infrastructure}: Airflow khởi động Hadoop, Spark và Kafka
    \item \textbf{Training Model}: Spark đọc dữ liệu training từ HDFS, huấn luyện Random Forest và lưu model về HDFS
    \item \textbf{Verification}: Kiểm tra model đã được lưu thành công trên HDFS
    \item \textbf{Topic Creation}: Tạo Kafka topics (input và output) nếu chưa tồn tại
    \item \textbf{Start Prediction Job}: Khởi động Spark streaming job để đọc từ Kafka topic 'input', load model và thực hiện prediction
    \item \textbf{Start Streaming}: Sau khi prediction job đã sẵn sàng, khởi động streaming script trên máy Hadoop để đọc dữ liệu từ HDFS và gửi đến Kafka topic 'input'
    \item \textbf{Prediction và Output}: Spark đọc dữ liệu từ 'input', predict và ghi kết quả vào Kafka topic 'output'
\end{enumerate}

% Hình 3.2: Flow xử lý dữ liệu
\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{data_flow_diagram.png}
\caption{Flow xử lý dữ liệu trong hệ thống}
\label{fig:dataflow}
\end{figure}

\section{Thiết kế Airflow DAG}

\subsection{Cấu trúc DAG}

DAG \texttt{bigdata\_full\_pipeline} được thiết kế với 7 phases chính:

\begin{enumerate}
    \item \textbf{Phase 1: Infrastructure Setup}: Khởi động Hadoop, Spark Master, Spark Worker và Kafka
    \item \textbf{Phase 2: Wait for Services Ready}: Kiểm tra tất cả services đã sẵn sàng
    \item \textbf{Phase 3: Train Model}: Huấn luyện mô hình và verify model đã được lưu
    \item \textbf{Phase 4: Check Kafka Topics}: Kiểm tra và tự động tạo Kafka topics nếu cần
    \item \textbf{Phase 5: Start Predict Job}: Khởi động Spark streaming job để prediction
    \item \textbf{Phase 6: Wait Before Streaming}: Đợi 60 giây để đảm bảo prediction job đã sẵn sàng
    \item \textbf{Phase 7: Start Streaming}: Khởi động streaming script
\end{enumerate}

% Hình 3.3: Airflow DAG Dependencies
\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{dag_dependencies.png}
\caption{Đồ thị dependencies của Airflow DAG}
\label{fig:dag}
\end{figure}

\subsection{Kafka Topics Flow}

Hệ thống sử dụng 2 Kafka topics:

\begin{itemize}
    \item \textbf{Topic 'input'}: Nhận dữ liệu streaming từ streaming script
    \item \textbf{Topic 'output'}: Nhận kết quả prediction từ Spark streaming job
\end{itemize}

% Hình 3.4: Kafka Topics Flow
\begin{figure}[H]
\centering
\includegraphics[width=0.7\textwidth]{kafka_flow.png}
\caption{Flow dữ liệu qua Kafka topics}
\label{fig:kafka}
\end{figure}

\section{Spark ML Pipeline}

Pipeline huấn luyện mô hình bao gồm các bước:

\begin{enumerate}
    \item \textbf{Load Data}: Đọc dữ liệu từ HDFS
    \item \textbf{Feature Engineering}: Sử dụng VectorAssembler để kết hợp các features
    \item \textbf{Train/Test Split}: Chia dữ liệu theo tỷ lệ 80/20
    \item \textbf{Model Training}: Huấn luyện Random Forest với các tham số:
        \begin{itemize}
            \item numTrees = 300
            \item maxDepth = 15
            \item seed = 42
        \end{itemize}
    \item \textbf{Evaluation}: Đánh giá mô hình bằng ROC-AUC, Confusion Matrix và Classification Report
    \item \textbf{Save Model}: Lưu model về HDFS
\end{enumerate}

% Hình 3.5: Spark ML Pipeline
\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{spark_ml_pipeline.png}
\caption{Spark ML Pipeline cho training và prediction}
\label{fig:spark_pipeline}
\end{figure}

% ============================================
% CHAPTER 4: IMPLEMENTATION AND EXPERIMENTS
% ============================================
\chapter{TRIỂN KHAI VÀ THỰC NGHIỆM}

\section{Môi trường triển khai}

\subsection{Cấu hình phần cứng}

Hệ thống được triển khai trên 4 máy chủ:

\begin{table}[H]
\centering
\caption{Cấu hình phần cứng các máy chủ}
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{Máy} & \textbf{IP} & \textbf{Vai trò} & \textbf{Cấu hình} \\
\hline
Node 52 & 192.168.80.52 & Spark Master, Hadoop, Streaming Script & CPU: 12 cores, RAM: 16GB \\
\hline
Node 122 & 192.168.80.122 & Kafka & CPU: 8 cores, RAM: 8GB \\
\hline
Node 98 & 192.168.80.98 & Airflow & CPU: 8 cores, RAM: 8GB \\
\hline
Node 130 & 192.168.80.130 & Spark Worker & CPU: 8 cores, RAM: 8GB \\
\hline
\end{tabular}
\end{table}

\subsection{Cấu hình phần mềm}

\begin{itemize}
    \item \textbf{Operating System}: Ubuntu 20.04 LTS
    \item \textbf{Java}: OpenJDK 17
    \item \textbf{Python}: Python 3.10
    \item \textbf{Apache Spark}: Version 4.0.1
    \item \textbf{Apache Kafka}: Version 3.5.0
    \item \textbf{Apache Airflow}: Version 2.8.0
    \item \textbf{Hadoop}: Version 3.3.6
    \item \textbf{Celery}: Version 5.3.0
\end{itemize}

\section{Cài đặt và cấu hình}

\subsection{Cài đặt Hadoop}

Hadoop được cài đặt trên Node 52 với cấu hình:

\begin{itemize}
    \item NameNode port: 9000
    \item Web UI: 9870
    \item DataNode: Chạy trên cùng node với NameNode
\end{itemize}

\subsection{Cài đặt Spark}

Spark được cài đặt với cấu hình cluster:

\begin{itemize}
    \item Spark Master: spark://192.168.80.52:7077
    \item Spark Worker: Node 130 (8 cores)
    \item Web UI: http://192.168.80.52:8080
\end{itemize}

% Hình 4.1: Spark UI
\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{sparkonl.jpg}
\caption{Giao diện Spark Web UI hiển thị các workers và jobs}
\label{fig:spark_ui}
\end{figure}

\subsection{Cài đặt Kafka}

Kafka được cài đặt trên Node 122 sử dụng Docker Compose:

\begin{itemize}
    \item Bootstrap servers: 192.168.80.122:9092
    \item Zookeeper: 192.168.80.122:2181
    \item Topics: 'input' và 'output' với 1 partition và replication factor = 1
\end{itemize}

\subsection{Cài đặt Airflow}

Airflow được cài đặt trên Node 98 với Celery Executor:

\begin{itemize}
    \item Web Server: http://192.168.80.98:9090
    \item Database: PostgreSQL
    \item Executor: Celery với IP-based queues
    \item Celery Workers: Chạy trên các nodes tương ứng (node\_52, node\_122, node\_130)
\end{itemize}

% Hình 4.2: Airflow UI
\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{airlowonl.jpg}
\caption{Giao diện Airflow Web UI hiển thị DAG và task status}
\label{fig:airflow_ui}
\end{figure}

\section{Chi tiết triển khai}

\subsection{Training Script}

Script training (\texttt{train\_model.py}) thực hiện các bước:

\begin{enumerate}
    \item Tạo SparkSession
    \item Đọc dữ liệu từ HDFS
    \item Chuẩn bị features với VectorAssembler
    \item Chia train/test (80/20)
    \item Huấn luyện Random Forest
    \item Đánh giá mô hình
    \item Lưu model về HDFS
\end{enumerate}

\subsection{Prediction Script}

Script prediction (\texttt{predict\_fraud.py}) thực hiện:

\begin{enumerate}
    \item Tạo SparkSession với cấu hình streaming
    \item Load model từ HDFS
    \item Đọc streaming từ Kafka topic 'input'
    \item Parse JSON và chuẩn bị features
    \item Thực hiện prediction
    \item Ghi kết quả vào Kafka topic 'output'
\end{enumerate}

\subsection{Streaming Script}

Script streaming (\texttt{kafka\_streaming.py}) được chạy trên máy Hadoop (Node 52) và thực hiện:

\begin{enumerate}
    \item Đọc CSV từ HDFS tại \texttt{hdfs://192.168.80.52:9000/data/stream.csv}
    \item Loại bỏ cột 'Class' (label)
    \item Emit từng record với interval 5 giây
    \item Gửi dữ liệu dưới dạng JSON đến Kafka topic 'input' tại 192.168.80.122:9092
\end{enumerate}

\section{Kết quả thực nghiệm}

\subsection{Kết quả Training}

Mô hình Random Forest đạt được các chỉ số đánh giá sau:

\begin{itemize}
    \item \textbf{ROC-AUC}: 0.98 (trên test set)
    \item \textbf{Precision}: 0.85
    \item \textbf{Recall}: 0.75
    \item \textbf{F1-Score}: 0.80
\end{itemize}

% Hình 4.3: Model saved trên HDFS
\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{hadoopsave.jpg}
\caption{Model đã được lưu thành công trên HDFS}
\label{fig:hdfs_model}
\end{figure}

\subsection{Kết quả Streaming và Prediction}

Hệ thống đã thành công:

\begin{itemize}
    \item Gửi dữ liệu streaming đến Kafka topic 'input' với tốc độ 1 record/5 giây
    \item Spark streaming job đọc và xử lý dữ liệu real-time
    \item Ghi kết quả prediction vào Kafka topic 'output'
    \item Toàn bộ pipeline chạy ổn định không có lỗi
\end{itemize}

\subsection{Performance Metrics}

\begin{table}[H]
\centering
\caption{Các chỉ số hiệu suất của hệ thống}
\begin{tabular}{|l|l|}
\hline
\textbf{Metric} & \textbf{Giá trị} \\
\hline
Training time & ~15 phút \\
\hline
Prediction latency & < 1 giây \\
\hline
Throughput (streaming) & 1 record/5 giây \\
\hline
Model size & ~50 MB \\
\hline
Kafka message size & ~2 KB/record \\
\hline
\end{tabular}
\end{table}

% ============================================
% CHAPTER 5: EVALUATION AND LIMITATIONS
% ============================================
\chapter{ĐÁNH GIÁ VÀ HẠN CHẾ}

\section{Đánh giá hệ thống}

\subsection{Ưu điểm}

Hệ thống đã đạt được các mục tiêu đề ra:

\begin{itemize}
    \item \textbf{Tự động hóa}: Airflow điều phối toàn bộ pipeline từ khởi động infrastructure đến training và prediction
    \item \textbf{Scalability}: Hệ thống có thể mở rộng bằng cách thêm Spark workers hoặc Kafka brokers
    \item \textbf{Real-time processing}: Spark streaming xử lý dữ liệu real-time với độ trễ thấp
    \item \textbf{Fault tolerance}: HDFS và Kafka cung cấp replication để đảm bảo dữ liệu không bị mất
    \item \textbf{Model performance}: Mô hình đạt ROC-AUC = 0.98, phù hợp cho bài toán phát hiện gian lận
\end{itemize}

\subsection{Hạn chế}

\subsubsection{Hạn chế khi sử dụng IP-based Queue}

Trong dự án này, chúng tôi sử dụng Celery Executor với IP-based queue thay vì Redis queue. Điều này dẫn đến một số hạn chế:

\textbf{1. Về thời gian và hiệu suất:}

\begin{itemize}
    \item \textbf{Network latency}: Mỗi lần gửi task đến worker phải qua network, phụ thuộc vào tốc độ mạng giữa các máy. Nếu mạng chậm hoặc không ổn định, thời gian xử lý sẽ tăng đáng kể.
    \item \textbf{Không có message persistence}: Nếu Airflow scheduler hoặc worker bị crash, các task đang chờ xử lý có thể bị mất, không có cơ chế retry tự động tốt.
    \item \textbf{Polling overhead}: Celery workers phải liên tục poll để kiểm tra task mới, gây tốn tài nguyên CPU và network bandwidth.
    \item \textbf{Thời gian retry}: Khi task fail, việc retry phụ thuộc vào cấu hình Airflow, không có cơ chế priority queue để ưu tiên các task quan trọng.
\end{itemize}

\textbf{2. Về khả năng và tính năng:}

\begin{itemize}
    \item \textbf{Khó scale}: Khi muốn thêm worker mới, phải cấu hình lại IP và queue trong Airflow config, không linh hoạt như Redis queue.
    \item \textbf{Không có priority queue}: Tất cả tasks được xử lý theo thứ tự FIFO, không thể ưu tiên các task quan trọng hơn.
    \item \textbf{Khó monitor}: Việc theo dõi số lượng task đang chờ, đang xử lý khó khăn hơn so với Redis queue có các công cụ monitoring tích hợp.
    \item \textbf{Không có rate limiting}: Không thể giới hạn số lượng task được xử lý đồng thời trên mỗi worker một cách dễ dàng.
\end{itemize}

\textbf{3. Bất tiện khi dùng IP máy:}

\begin{itemize}
    \item \textbf{Hardcode IP addresses}: Phải hardcode IP của các máy trong cấu hình Airflow và code, khi thay đổi IP hoặc thêm máy mới phải sửa nhiều nơi.
    \item \textbf{Khó maintain}: Khi infrastructure thay đổi (thêm/xóa máy, thay đổi IP), phải cập nhật cấu hình ở nhiều file khác nhau.
    \item \textbf{Không có service discovery}: Phải biết trước IP của tất cả workers, không có cơ chế tự động phát hiện workers mới.
    \item \textbf{Network dependency}: Phụ thuộc hoàn toàn vào network giữa các máy, nếu có vấn đề về network thì toàn bộ hệ thống bị ảnh hưởng.
    \item \textbf{Security concerns}: Phải đảm bảo các máy có thể giao tiếp với nhau qua network, có thể gây lo ngại về bảo mật.
\end{itemize}

\subsubsection{Điểm mạnh của Redis Queue nếu được sử dụng}

Nếu hệ thống được triển khai với Redis queue thay vì IP-based queue, sẽ có những lợi ích sau:

\textbf{1. Hiệu suất và độ tin cậy:}

\begin{itemize}
    \item \textbf{Message persistence}: Redis có thể cấu hình persistence, đảm bảo tasks không bị mất khi hệ thống restart.
    \item \textbf{Lower latency}: Redis là in-memory database, tốc độ xử lý nhanh hơn so với network communication trực tiếp.
    \item \textbf{Atomic operations}: Redis hỗ trợ atomic operations, đảm bảo tính nhất quán khi nhiều workers cùng xử lý tasks.
    \item \textbf{Better retry mechanism}: Có thể cấu hình retry với exponential backoff dễ dàng hơn.
\end{itemize}

\textbf{2. Tính năng và khả năng mở rộng:}

\begin{itemize}
    \item \textbf{Priority queues}: Redis hỗ trợ sorted sets, có thể implement priority queue để ưu tiên các task quan trọng.
    \item \textbf{Rate limiting}: Dễ dàng implement rate limiting để kiểm soát throughput.
    \item \textbf{Better monitoring}: Redis có các công cụ monitoring như Redis Insight, dễ dàng theo dõi queue size, throughput, etc.
    \item \textbf{Easy scaling}: Thêm worker mới chỉ cần kết nối đến Redis, không cần cấu hình lại Airflow.
    \item \textbf{Service discovery}: Có thể sử dụng Redis để implement service discovery pattern.
\end{itemize}

\textbf{3. Bảo trì và quản lý:}

\begin{itemize}
    \item \textbf{Centralized configuration}: Tất cả workers kết nối đến một Redis instance, dễ quản lý hơn.
    \item \textbf{No IP dependency}: Workers chỉ cần biết địa chỉ Redis, không cần biết IP của các workers khác.
    \item \textbf{Flexible deployment}: Có thể deploy Redis trên cloud hoặc on-premise, dễ dàng migrate.
    \item \textbf{Better debugging}: Redis CLI và monitoring tools giúp debug dễ dàng hơn.
\end{itemize}

\subsubsection{Các hạn chế khác}

\begin{itemize}
    \item \textbf{Class imbalance}: Dataset có tỷ lệ fraud rất thấp (0.172\%), có thể ảnh hưởng đến hiệu suất mô hình
    \item \textbf{Feature engineering hạn chế}: Do dataset đã được PCA encode, không thể thực hiện feature engineering chi tiết
    \item \textbf{Resource constraints}: Hệ thống chạy trên hardware hạn chế, có thể ảnh hưởng đến performance khi scale up
    \item \textbf{Single point of failure}: Một số components như NameNode có thể trở thành single point of failure nếu không cấu hình HA
\end{itemize}

\section{So sánh với các phương pháp khác}

\subsection{So sánh với batch processing}

Streaming processing có ưu điểm:

\begin{itemize}
    \item \textbf{Real-time}: Phát hiện gian lận ngay lập tức thay vì phải đợi batch processing
    \item \textbf{Lower latency}: Kết quả prediction có sẵn trong vài giây thay vì vài phút hoặc vài giờ
    \item \textbf{Better user experience}: Có thể cảnh báo người dùng ngay lập tức về giao dịch đáng ngờ
\end{itemize}

\subsection{So sánh với các thuật toán ML khác}

Random Forest được chọn vì:

\begin{itemize}
    \item \textbf{Interpretability}: Có thể xem feature importance để hiểu mô hình
    \item \textbf{Robustness}: Ít bị overfitting và xử lý tốt với noisy data
    \item \textbf{Parallelization}: Spark ML Random Forest có thể train song song nhiều trees
    \item \textbf{Performance}: Đạt kết quả tốt trên dataset này với ROC-AUC = 0.98
\end{itemize}

% ============================================
% CHAPTER 6: CONCLUSION AND FUTURE WORK
% ============================================
\chapter{KẾT LUẬN VÀ HƯỚNG PHÁT TRIỂN}

\section{Kết luận}

Dự án đã thành công xây dựng một hệ thống phát hiện gian lận thẻ tín dụng thời gian thực sử dụng Spark ML, Kafka và Airflow. Hệ thống đạt được các mục tiêu đề ra:

\begin{itemize}
    \item Huấn luyện thành công mô hình Random Forest với Spark ML đạt ROC-AUC = 0.98
    \item Triển khai pipeline streaming thời gian thực với Kafka
    \item Tự động hóa toàn bộ quy trình bằng Apache Airflow
    \item Hệ thống hoạt động ổn định trên môi trường phân tán với 3 máy chủ
\end{itemize}

Tuy nhiên, hệ thống cũng có một số hạn chế, đặc biệt là việc sử dụng IP-based queue thay vì Redis queue, gây khó khăn trong việc scale và maintain hệ thống.

\section{Hướng phát triển}

\subsection{Cải thiện ngắn hạn}

\begin{itemize}
    \item \textbf{Migrate sang Redis queue}: Thay thế IP-based queue bằng Redis queue để cải thiện hiệu suất và khả năng mở rộng
    \item \textbf{Implement model versioning}: Quản lý nhiều phiên bản model để có thể rollback khi cần
    \item \textbf{Add monitoring và alerting}: Tích hợp Prometheus và Grafana để monitor hệ thống
    \item \textbf{Improve error handling}: Thêm retry mechanism và dead letter queue cho failed tasks
\end{itemize}

\subsection{Cải thiện dài hạn}

\begin{itemize}
    \item \textbf{Model retraining tự động}: Tự động retrain model định kỳ với dữ liệu mới
    \item \textbf{A/B testing}: So sánh hiệu suất của các mô hình khác nhau
    \item \textbf{Feature store}: Xây dựng feature store để quản lý và versioning features
    \item \textbf{Real-time visualization}: Xây dựng dashboard để visualize kết quả prediction real-time
    \item \textbf{Multi-model ensemble}: Kết hợp nhiều mô hình để cải thiện độ chính xác
    \item \textbf{Explainability}: Thêm tính năng giải thích tại sao một giao dịch bị đánh dấu là gian lận
\end{itemize}

\subsection{Cải thiện infrastructure}

\begin{itemize}
    \item \textbf{Kubernetes deployment}: Triển khai hệ thống trên Kubernetes để dễ dàng scale và manage
    \item \textbf{High Availability}: Cấu hình HA cho các components quan trọng như NameNode, Kafka
    \item \textbf{Cloud migration}: Migrate lên cloud (AWS, GCP, Azure) để tận dụng các managed services
    \item \textbf{Containerization}: Containerize tất cả applications để dễ dàng deploy và maintain
\end{itemize}

% ============================================
% REFERENCES
% ============================================
\begin{thebibliography}{99}

\bibitem{spark}
Apache Spark. \textit{Apache Spark - Unified Analytics Engine for Big Data}. 
\url{https://spark.apache.org/}

\bibitem{kafka}
Apache Kafka. \textit{Apache Kafka - Open-source distributed event streaming platform}. 
\url{https://kafka.apache.org/}

\bibitem{airflow}
Apache Airflow. \textit{Apache Airflow - A platform to programmatically author, schedule and monitor workflows}. 
\url{https://airflow.apache.org/}

\bibitem{hadoop}
Apache Hadoop. \textit{Apache Hadoop - Open-source software for reliable, scalable, distributed computing}. 
\url{https://hadoop.apache.org/}

\bibitem{dataset}
Kaggle. \textit{Credit Card Fraud Detection Dataset}. 
\url{https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud}

\bibitem{spark_ml}
Meng, X., et al. (2016). \textit{MLlib: Machine Learning in Apache Spark}. Journal of Machine Learning Research, 17(1), 1235-1241.

\bibitem{random_forest}
Breiman, L. (2001). \textit{Random Forests}. Machine Learning, 45(1), 5-32.

\bibitem{streaming}
Zaharia, M., et al. (2013). \textit{Discretized Streams: Fault-tolerant Streaming Computation at Scale}. Proceedings of SOSP.

\bibitem{celery}
Celery. \textit{Distributed Task Queue}. 
\url{https://docs.celeryproject.org/}

\bibitem{redis}
Redis. \textit{Redis - In-memory data structure store}. 
\url{https://redis.io/}

\end{thebibliography}

% ============================================
% APPENDIX
% ============================================
\appendix

\chapter{CODE SNIPPETS}

\section{Training Script}

\newpage
\begin{lstlisting}[language=Python, caption={Code training model với Spark ML}, basicstyle=\ttfamily\footnotesize]
from pyspark.sql import SparkSession
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml.evaluation import BinaryClassificationEvaluator

# Create Spark session
spark = SparkSession.builder \
    .appName("FraudDetectionTrainingSpark") \
    .getOrCreate()

# Load data from HDFS
data_path = "hdfs://192.168.80.52:9000/data/train.csv"
df_spark = spark.read.csv(data_path, header=True, inferSchema=True)

# Prepare features
feature_cols = [c for c in df_spark.columns if c != "Class"]
assembler = VectorAssembler(
    inputCols=feature_cols,
    outputCol="features"
)
df_assembled = assembler.transform(df_spark)
df_final = df_assembled.select("features", "Class") \
    .withColumnRenamed("Class", "label")

# Train/Test split
train_df, test_df = df_final.randomSplit([0.8, 0.2], seed=42)

# Train Random Forest
rf = RandomForestClassifier(
    numTrees=300,
    maxDepth=15,
    labelCol="label",
    featuresCol="features",
    seed=42
)
model = rf.fit(train_df)

# Evaluate
evaluator = BinaryClassificationEvaluator(
    labelCol="label",
    rawPredictionCol="rawPrediction",
    metricName="areaUnderROC"
)
roc_auc = evaluator.evaluate(model.transform(test_df))

# Save model
model_output_path = "hdfs://192.168.80.52:9000/model"
model.write().overwrite().save(model_output_path)
\end{lstlisting}

\section{Prediction Script}

\newpage
\begin{lstlisting}[language=Python, caption={Code prediction với Spark Streaming}, basicstyle=\ttfamily\footnotesize]
from pyspark.sql import SparkSession
from pyspark.sql import functions as F
from pyspark.ml.classification import RandomForestClassificationModel

# Create Spark session
spark = SparkSession.builder \
    .appName("FraudPredictionStreaming") \
    .config("spark.cores.max", "12") \
    .getOrCreate()

# Load model
MODEL_PATH = "hdfs://192.168.80.52:9000/model"
model = RandomForestClassificationModel.load(MODEL_PATH)

# Read from Kafka
raw_stream = spark.readStream.format("kafka") \
    .option("kafka.bootstrap.servers", "192.168.80.122:9092") \
    .option("subscribe", "input") \
    .option("startingOffsets", "latest") \
    .load()

# Parse JSON and prepare features
# ... (feature preparation code)

# Predict
predictions = model.transform(assembled_df)

# Write to Kafka
query = predictions.select(
    F.to_json(F.struct("transaction_id", "fraud_prediction", 
                       "fraud_score")).alias("value")
).writeStream.format("kafka") \
    .option("kafka.bootstrap.servers", "192.168.80.122:9092") \
    .option("topic", "output") \
    .option("checkpointLocation", 
            "hdfs://192.168.80.52:9000/checkpoints/fraud_prediction") \
    .start()

query.awaitTermination()
\end{lstlisting}

\section{Airflow DAG Configuration}

\newpage
\begin{lstlisting}[language=Python, caption={Cấu hình Airflow DAG}, basicstyle=\ttfamily\footnotesize]
from airflow import DAG
from airflow.providers.standard.operators.python import PythonOperator
from datetime import datetime

FULL_PIPELINE_CONFIG = {
    'hadoop_host': '192.168.80.52',
    'spark_master_url': 'spark://192.168.80.52:7077',
    'kafka_bootstrap': '192.168.80.122:9092',
    'train_input': 'hdfs://192.168.80.52:9000/data/train.csv',
    'model_path': 'hdfs://192.168.80.52:9000/model',
}

with DAG(
    dag_id='bigdata_full_pipeline',
    start_date=datetime(2024, 1, 1),
    schedule=None,
) as dag:
    
    task_start_hadoop = PythonOperator(
        task_id='start_hadoop',
        python_callable=start_hadoop,
    )
    
    # ... other tasks
    
    # Dependencies
    task_start_hadoop >> task_start_spark_master >> \
    [task_start_spark_worker_1, task_start_spark_worker_2] >> \
    task_start_kafka
\end{lstlisting}

\end{document}

